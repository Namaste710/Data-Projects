{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column names\n",
    "cols = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "# reading the .data file \n",
    "df = pd.read_csv('./auto-mpg.data', na_values='?', names=cols, comment='\\t', sep=' ', skipinitialspace=True)\n",
    "\n",
    "# make a copy\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_preproc_pipeline() -> Pipeline:\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    num_pipeline = Pipeline([(\"imputer\", imputer), \n",
    "                             (\"scaler\", scaler)], \n",
    "                            verbose=True)\n",
    "    \n",
    "    return num_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_preproc_pipeline() -> Pipeline:\n",
    "    ohe = OneHotEncoder()\n",
    "    \n",
    "    cat_pipeline = Pipeline([(\"one_hot_encoder\", ohe)], \n",
    "                            verbose=True)\n",
    "    \n",
    "    return cat_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_preproc_ct(X_input: pd.DataFrame, num_pipeline: Pipeline, cat_pipeline: Pipeline) -> tuple[pd.DataFrame, ColumnTransformer]:\n",
    "\n",
    "    num_attributes = X_input.select_dtypes(include=[\"float\", \"int64\"]).columns\n",
    "\n",
    "    cat_attributes = X_input.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    full_pipeline = ColumnTransformer(\n",
    "        [(\"cat\", cat_pipeline, cat_attributes), \n",
    "         (\"num\", num_pipeline, num_attributes)],\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    preprocessed_data = full_pipeline.fit_transform(X_input)\n",
    "\n",
    "    return preprocessed_data, full_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[\"Origin\"] = df_original[\"Origin\"].map({1: 'India', 2: 'USA', 3: 'Germany'})\n",
    "\n",
    "# split the training and test set into features (X) and label (y)\n",
    "X_train = df_original.drop('MPG', axis=1)\n",
    "y_train = df_original['MPG'].copy()\n",
    "\n",
    "X_test = df_original.drop('MPG', axis=1)\n",
    "y_test = df_original['MPG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 1) Processing one_hot_encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 2) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 2) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing scaler, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 2) Processing num, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing one_hot_encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 2) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 2) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing scaler, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 2) Processing num, total=   0.0s\n",
      "MSE:  11.65659485866891\n",
      "RMSE:  3.414175575255161\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = num_preproc_pipeline()\n",
    "cat_pipeline = cat_preproc_pipeline()\n",
    "\n",
    "X_train_prepr, train_pipeline = full_preproc_ct(X_train, num_pipeline, cat_pipeline)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_prepr, y_train)\n",
    "\n",
    "X_test_prepr, test_pipeline = full_preproc_ct(X_test, num_pipeline, cat_pipeline)\n",
    "\n",
    "y_pred_lreg = lreg.predict(X_test_prepr)\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_pred_lreg, y_test))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_pred_lreg, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and test set into features (X) and label (y)\n",
    "X_train = strat_train_set.drop('MPG', axis=1)\n",
    "y_train = strat_train_set['MPG'].copy()\n",
    "\n",
    "X_test = strat_test_set.drop('MPG', axis=1)\n",
    "y_test = strat_test_set['MPG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering with the BaseEstimator and Transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "acceleration_pos, horsepower_pos, cylinders_pos = 4, 2, 0\n",
    "# acceleration_per_cylinder\n",
    "# acceleration_per_horsepower\n",
    "class FeatureCreator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, acc_on_power=True): \n",
    "        self.acc_on_power = acc_on_power\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        acc_on_cyl = X[:, acceleration_pos] / X[:, horsepower_pos]\n",
    "        if self.acc_on_power:\n",
    "            acc_on_power = X[:, acceleration_pos] / X[:, horsepower_pos]\n",
    "            return np.c_[X, acc_on_power, acc_on_cyl]\n",
    "        return np.c_[X, acc_on_cyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def numerical_pipeline_transformer(df):\n",
    "    '''Preprocesses numerical columns in the DataFrame\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        numerical_attr: DataFrame with only numerical columns\n",
    "        numerical_pipeline: The pipeline object\n",
    "    '''\n",
    "    numerical = ['float', 'int64']\n",
    "\n",
    "    numerical_data = df.select_dtypes(include=numerical)\n",
    "\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('feature_creator', FeatureCreator()),\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "    return numerical_data, numerical_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def full_pipeline(df):\n",
    "    '''Completely preprocesses the DataFrame (numerical and categorical columns)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "\n",
    "    Returns:\n",
    "        preprocessed_data: Preprocessed DataFrame\n",
    "    '''\n",
    "    numerical_attributes, numerical_pipeline = numerical_pipeline_transformer(df)\n",
    "    numerical_attributes = list(numerical_attributes)\n",
    "    cat_attributes = ['Origin']\n",
    "    \n",
    "    full_pipeline = ColumnTransformer([\n",
    "        ('numerical', numerical_pipeline, numerical_attributes),\n",
    "        ('cat', OneHotEncoder(), cat_attributes)\n",
    "    ])\n",
    "    preprocessed_data = full_pipeline.fit_transform(df)\n",
    "    print(preprocessed_data[0])\n",
    "    return preprocessed_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.85657842 -1.07804475 -1.15192977 -1.17220298  1.21586943 -0.54436373\n",
      "  1.70952741  1.70952741  1.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "X_train_prepr = preprocess_origin_col(X_train)\n",
    "X_train_prepr = full_pipeline(X_train_prepr)\n",
    "\n",
    "\n",
    "#MSE:  10.823784975177286\n",
    "#RMSE:  3.289952123538774"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.14354699e-01  4.60890510e-01 -1.58316350e-01  4.34776107e-01\n",
      "  6.35531432e-01 -5.44299585e-01  9.43564694e-04  9.43564694e-04\n",
      "  0.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      "MSE:  10.737753984271475\n",
      "RMSE:  3.276851230109703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_prepr, y_train)\n",
    "\n",
    "X_test_prepr = preprocess_origin_col(X_test)\n",
    "X_test_prepr = full_pipeline(X_test_prepr)\n",
    "\n",
    "y_pred_lreg = lreg.predict(X_test_prepr)\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_pred_lreg, y_test))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_pred_lreg, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.052042580702212"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lreg, X_train_prepr, y_train, scoring='neg_mean_squared_error',\n",
    "cv=10)\n",
    "np.sqrt(-scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}\n",
    "]\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, scoring='neg_mean_squared_error', return_train_score=True, cv=10)\n",
    "\n",
    "grid_search.fit(X_train_prepr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.4776328471438798 with {'max_features': 2, 'n_estimators': 3}\n",
      "RMSE: 2.9242253816457597 with {'max_features': 2, 'n_estimators': 10}\n",
      "RMSE: 2.899842097457752 with {'max_features': 2, 'n_estimators': 30}\n",
      "RMSE: 3.2799203441787586 with {'max_features': 4, 'n_estimators': 3}\n",
      "RMSE: 2.7902839435955435 with {'max_features': 4, 'n_estimators': 10}\n",
      "RMSE: 2.8169584110774775 with {'max_features': 4, 'n_estimators': 30}\n",
      "RMSE: 3.2182991602346456 with {'max_features': 6, 'n_estimators': 3}\n",
      "RMSE: 2.8974951936418147 with {'max_features': 6, 'n_estimators': 10}\n",
      "RMSE: 2.7022684392454304 with {'max_features': 6, 'n_estimators': 30}\n",
      "RMSE: 3.012998683422919 with {'max_features': 8, 'n_estimators': 3}\n",
      "RMSE: 2.816742060731431 with {'max_features': 8, 'n_estimators': 10}\n",
      "RMSE: 2.6680899259670006 with {'max_features': 8, 'n_estimators': 30}\n",
      "RMSE: 3.3715944088111907 with {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "RMSE: 3.0058357705362884 with {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "RMSE: 2.9969100724043845 with {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "RMSE: 2.822591860058365 with {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "RMSE: 3.0922438814269197 with {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "RMSE: 2.75112258428997 with {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cv_scores = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cv_scores['mean_test_score'], cv_scores['params']):\n",
    "    print(f'RMSE: {np.sqrt(-mean_score)} with {(params)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acc_on_power', 0.023740526158846476),\n",
       " ('acc_on_cyl', 0.01637800280434033),\n",
       " ('Weight', 0.19584452225887036),\n",
       " ('Model Year', 0.11485079241459735),\n",
       " ('Horsepower', 0.1326374072778818),\n",
       " ('Displacement', 0.27648206423683364),\n",
       " ('Cylinders', 0.21844532595469468),\n",
       " ('Acceleration', 0.015680319872427295)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "extra_features = ['acc_on_power', 'acc_on_cyl']\n",
    "numerical = ['float64', 'int64']\n",
    "numerical_features = list(X_train.select_dtypes(include=numerical))\n",
    "\n",
    "numerical_features = numerical_features + extra_features\n",
    "sorted(zip(numerical_features, feature_importances), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_rf = final_model.predict(X_test_prepr)\n",
    "final_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "final_rmse = np.sqrt(final_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(input_data, model):\n",
    "    if type(input_data) == dict:\n",
    "        df = pd.DataFrame(input_data)\n",
    "    else:\n",
    "        df = input_data\n",
    "    \n",
    "    df = preprocess_origin_col(df)\n",
    "    df = full_pipeline(df)\n",
    "    y_pred = model.predict(df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving the model\n",
    "with open('model.bin', 'wb') as f_out:\n",
    "    pickle.dump(final_model, f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=8, n_estimators=30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the model\n",
    "import pickle\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "    f_in.close()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.54333333, 17.64333333, 21.29333333])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_data = {\n",
    "    'Cylinders': [4, 6, 8],\n",
    "    'Displacement': [155.0, 160.0, 165.5],\n",
    "    'Horsepower': [93.0, 130.0, 98.0],\n",
    "    'Weight': [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration': [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78],\n",
    "    'Origin': [3, 2, 1]\n",
    "}\n",
    "predict_y(vehicle_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_boston\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 10,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"boston.log\",\n",
    "}\n",
    "X_train, y_train = load_boston(return_X_y=True)\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,\n",
    "           **automl_settings)\n",
    "# Predict\n",
    "print(automl.predict(X_train))\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"postgres://postgres:postgrespw@localhost:49153\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\"\"\")\n",
    "for table in cur.fetchall():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('postgres',)\n",
      "('template1',)\n",
      "('template0',)\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT datname FROM pg_database\")\n",
    "for table in cur.fetchall():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19a91482ee4d38e3a9ae386a52bde6b79fc45b701cc986d0486eb22f2036905a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mlflow_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
