{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "myenv",
   "display_name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column names\n",
    "cols = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "# reading the .data file \n",
    "df = pd.read_csv('./auto-mpg.data', na_values='?', names=cols, comment='\\t', sep=' ', skipinitialspace=True)\n",
    "\n",
    "# make a copy\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# splitting data into stratified train/test to keep distributions between categories\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df['Cylinders']):\n",
    "    strat_train_set = df.iloc[train_index]\n",
    "    strat_test_set = df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and test set into features (X) and label (y)\n",
    "X_train = strat_train_set.drop('MPG', axis=1)\n",
    "y_train = strat_train_set['MPG'].copy()\n",
    "\n",
    "X_test = strat_test_set.drop('MPG', axis=1)\n",
    "y_test = strat_test_set['MPG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess origin column\n",
    "def preprocess_origin_col(df):\n",
    "    df['Origin'] = df['Origin'].map({1: 'India', 2: 'USA', 3: 'Germany'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering with the BaseEstimator and Transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "acceleration_pos, horsepower_pos, cylinders_pos = 4, 2, 0\n",
    "\n",
    "class FeatureCreator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, acc_on_power=True): \n",
    "        self.acc_on_power = acc_on_power\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        acc_on_cyl = X[:, acceleration_pos] / X[:, horsepower_pos]\n",
    "        if self.acc_on_power:\n",
    "            acc_on_power = X[:, acceleration_pos] / X[:, horsepower_pos]\n",
    "            return np.c_[X, acc_on_power, acc_on_cyl]\n",
    "        return np.c_[X, acc_on_cyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def numerical_pipeline_transformer(df):\n",
    "    '''Preprocesses numerical columns in the DataFrame\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        numerical_attr: DataFrame with only numerical columns\n",
    "        numerical_pipeline: The pipeline object\n",
    "    '''\n",
    "    numerical = ['float', 'int64']\n",
    "\n",
    "    numerical_data = df.select_dtypes(include=numerical)\n",
    "\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('feature_creator', FeatureCreator()),\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "    return numerical_data, numerical_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def full_pipeline(df):\n",
    "    '''Completely preprocesses the DataFrame (numerical and categorical columns)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "\n",
    "    Returns:\n",
    "        preprocessed_data: Preprocessed DataFrame\n",
    "    '''\n",
    "    numerical_attributes, numerical_pipeline = numerical_pipeline_transformer(df)\n",
    "    numerical_attributes = list(numerical_attributes)\n",
    "    cat_attributes = ['Origin']\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        ('numerical', numerical_pipeline, numerical_attributes),\n",
    "        ('cat', OneHotEncoder(), cat_attributes)\n",
    "    ])\n",
    "    preprocessed_data = full_pipeline.fit_transform(df)\n",
    "    return preprocessed_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepr = preprocess_origin_col(X_train)\n",
    "X_train_prepr = full_pipeline(X_train_prepr)"
   ]
  },
  {
   "source": [
    "# Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE:  10.737753984271482\nRMSE:  3.2768512301097044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_prepr, y_train)\n",
    "\n",
    "X_test_prepr = preprocess_origin_col(X_test)\n",
    "X_test_prepr = full_pipeline(X_test_prepr)\n",
    "\n",
    "y_pred_lreg = lreg.predict(X_test_prepr)\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_pred_lreg, y_test))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_pred_lreg, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.052042580702212"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lreg, X_train_prepr, y_train, scoring='neg_mean_squared_error',\n",
    "cv=10)\n",
    "np.sqrt(-scores).mean()"
   ]
  },
  {
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}\n",
    "]\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(rf_reg, param_grid, scoring='neg_mean_squared_error', return_train_score=True, cv=10)\n",
    "\n",
    "grid_search.fit(X_train_prepr, y_train)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 3.4776328471438798 with {'max_features': 2, 'n_estimators': 3}\nRMSE: 2.9242253816457597 with {'max_features': 2, 'n_estimators': 10}\nRMSE: 2.899842097457752 with {'max_features': 2, 'n_estimators': 30}\nRMSE: 3.2799203441787586 with {'max_features': 4, 'n_estimators': 3}\nRMSE: 2.7902839435955435 with {'max_features': 4, 'n_estimators': 10}\nRMSE: 2.8169584110774775 with {'max_features': 4, 'n_estimators': 30}\nRMSE: 3.2182991602346456 with {'max_features': 6, 'n_estimators': 3}\nRMSE: 2.8974951936418147 with {'max_features': 6, 'n_estimators': 10}\nRMSE: 2.7022684392454304 with {'max_features': 6, 'n_estimators': 30}\nRMSE: 3.012998683422919 with {'max_features': 8, 'n_estimators': 3}\nRMSE: 2.816742060731431 with {'max_features': 8, 'n_estimators': 10}\nRMSE: 2.6680899259670006 with {'max_features': 8, 'n_estimators': 30}\nRMSE: 3.3715944088111907 with {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\nRMSE: 3.0058357705362884 with {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\nRMSE: 2.9969100724043845 with {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\nRMSE: 2.822591860058365 with {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\nRMSE: 3.0922438814269197 with {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\nRMSE: 2.75112258428997 with {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cv_scores = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cv_scores['mean_test_score'], cv_scores['params']):\n",
    "    print(f'RMSE: {np.sqrt(-mean_score)} with {(params)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('acc_on_power', 0.023740526158846476),\n",
       " ('acc_on_cyl', 0.01637800280434033),\n",
       " ('Weight', 0.19584452225887036),\n",
       " ('Model Year', 0.11485079241459735),\n",
       " ('Horsepower', 0.1326374072778818),\n",
       " ('Displacement', 0.27648206423683364),\n",
       " ('Cylinders', 0.21844532595469468),\n",
       " ('Acceleration', 0.015680319872427295)]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "extra_features = ['acc_on_power', 'acc_on_cyl']\n",
    "numerical = ['float64', 'int64']\n",
    "numerical_features = list(X_train.select_dtypes(include=numerical))\n",
    "\n",
    "numerical_features = numerical_features + extra_features\n",
    "sorted(zip(numerical_features, feature_importances), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_rf = final_model.predict(X_test_prepr)\n",
    "final_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "final_rmse = np.sqrt(final_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(input_data, model):\n",
    "    if type(input_data) == dict:\n",
    "        df = pd.DataFrame(input_data)\n",
    "    else:\n",
    "        df = input_data\n",
    "    \n",
    "    df = preprocess_origin_col(df)\n",
    "    df = full_pipeline(df)\n",
    "    y_pred = model.predict(df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving the model\n",
    "with open('model.bin', 'wb') as f_out:\n",
    "    pickle.dump(final_model, f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=8, n_estimators=30)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# open the model\n",
    "import pickle\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "    f_in.close()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([33.54333333, 17.64333333, 21.29333333])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "vehicle_data = {\n",
    "    'Cylinders': [4, 6, 8],\n",
    "    'Displacement': [155.0, 160.0, 165.5],\n",
    "    'Horsepower': [93.0, 130.0, 98.0],\n",
    "    'Weight': [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration': [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78],\n",
    "    'Origin': [3, 2, 1]\n",
    "}\n",
    "predict_y(vehicle_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}